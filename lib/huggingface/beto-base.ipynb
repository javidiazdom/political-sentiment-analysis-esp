{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5532ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from utils import TweetsDataset\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687d44d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "model = transformers.BertForSequenceClassification.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6235c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/development.csv\")\n",
    "df = pd.DataFrame({\n",
    "    \"tweets\": df[\"tweet\"],\n",
    "    \"labels\": df[\"ideology_multiclass\"].map({'moderate_left': 0, 'moderate_right': 1, \"left\": 2, \"right\": 3})\n",
    "})\n",
    "df_train, df_val = TweetsDataset.split_test_val(df, valid_size=0.15)\n",
    "train_data_loader = TweetsDataset.create_data_loader(df_train, tokenizer, batch_size=8)\n",
    "valid_data_loader = TweetsDataset.create_data_loader(df_val, tokenizer, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6607a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "EPOCHS = 8\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = len(train_data_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77883c20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "----------\n",
      "\u001b[KTrain loss: 0.506 Accuracy: 0.437\n",
      "Validation loss 0.474 Accuracy: 0.5 F1 score: 0.5\n",
      "\n",
      "Epoch 2/8\n",
      "----------\n",
      "\u001b[KTrain loss: 0.434 Accuracy: 0.574\n",
      "Validation loss 0.474 Accuracy: 0.5 F1 score: 0.5\n",
      "\n",
      "Epoch 3/8\n",
      "----------\n",
      "\u001b[KTrain loss: 0.434 Accuracy: 0.576\n",
      "Validation loss 0.474 Accuracy: 0.5 F1 score: 0.5\n",
      "\n",
      "Epoch 4/8\n",
      "----------\n",
      "\u001b[KTrain loss: 0.434 Accuracy: 0.573\n",
      "Validation loss 0.474 Accuracy: 0.5 F1 score: 0.5\n",
      "\n",
      "Epoch 5/8\n",
      "----------\n",
      "\u001b[KTrain loss: 0.434 Accuracy: 0.57\n",
      "Validation loss 0.474 Accuracy: 0.5 F1 score: 0.5\n",
      "\n",
      "Epoch 6/8\n",
      "----------\n",
      "\u001b[KTrain loss: 0.435 Accuracy: 0.573\n",
      "Validation loss 0.474 Accuracy: 0.5 F1 score: 0.5\n",
      "\n",
      "Epoch 7/8\n",
      "----------\n",
      "\u001b[KTrain loss: 0.434 Accuracy: 0.573\n",
      "Validation loss 0.474 Accuracy: 0.5 F1 score: 0.5\n",
      "\n",
      "Epoch 8/8\n",
      "----------\n",
      "\u001b[KTrain loss: 0.434 Accuracy: 0.572\n",
      "Validation loss 0.474 Accuracy: 0.5 F1 score: 0.5\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'train_acc': [0.4366830065359477,\n",
       "              0.5741013071895424,\n",
       "              0.575735294117647,\n",
       "              0.5727124183006536,\n",
       "              0.5695261437908496,\n",
       "              0.5727124183006536,\n",
       "              0.5726307189542483,\n",
       "              0.572140522875817],\n",
       "             'train_loss': [0.5056820976773119,\n",
       "              0.43428898354371387,\n",
       "              0.4341222838249082,\n",
       "              0.43426128835265154,\n",
       "              0.4342885223576446,\n",
       "              0.43450173209695253,\n",
       "              0.434234154049088,\n",
       "              0.4343612019435253],\n",
       "             'val_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "             'val_loss': [0.4735356524034783,\n",
       "              0.4735356524034783,\n",
       "              0.4735356524034783,\n",
       "              0.4735356524034783,\n",
       "              0.4735356524034783,\n",
       "              0.4735356524034783,\n",
       "              0.4735356524034783,\n",
       "              0.4735356524034783],\n",
       "             'f_score': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from utils import Model\n",
    "history = defaultdict(list)\n",
    "Model.train(EPOCHS, model, train_data_loader, optimizer, device, scheduler, history, len(df_train), len(df_val), valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58513ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'berto-base-cased.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f091cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.497 Accuracy: 0.448\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'concat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3444\\2856311907.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtest_data_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTweetsDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_data_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mResults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ideology-multiclass\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mH:\\GitHub\\political-sentiment-analysis-esp\\lib\\huggingface\\utils\\Results.py\u001b[0m in \u001b[0;36madd_result\u001b[1;34m(model, class_, acc, loss, f1)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../results.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     results = results.concat(pd.DataFrame({\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;34m\"model\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5573\u001b[0m         ):\n\u001b[0;32m   5574\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5577\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'concat'"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "from utils import Results, Model\n",
    "model = transformers.BertForSequenceClassification.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", num_labels=4)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('berto-base-cased.bin'))\n",
    "df_test = pd.read_csv('../../data/development_test.csv')\n",
    "df_test = pd.DataFrame({\n",
    "    \"tweets\": df_test[\"tweet\"],\n",
    "    \"labels\": df_test[\"ideology_multiclass\"].map({'moderate_left': 0, 'moderate_right': 1, \"left\": 2, \"right\": 3})\n",
    "})\n",
    "test_data_loader = TweetsDataset.create_data_loader(df_test, tokenizer)\n",
    "acc, loss, f1 = Model.test(model, test_data_loader, device, len(df_test))\n",
    "Results.add_result(\"berto-base-cased\", \"ideology-multiclass\", acc, loss, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "983b2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "results = pd.read_csv(\"../results.csv\")\n",
    "results = pd.concat([results,pd.DataFrame({\n",
    "    \"model\": \"berto-base-uncased\",\n",
    "    \"class\": \"ideology-multiclass\",\n",
    "    \"loss\": loss,\n",
    "    \"f1score\": f1,\n",
    "    \"accuracy\": acc,\n",
    "    \"train_time\": date.now()\n",
    "}, index=[0])]).reset_index(drop=True)\n",
    "results.reset_index()\n",
    "results.to_csv(\"../results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
