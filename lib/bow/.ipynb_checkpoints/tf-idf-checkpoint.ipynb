{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "810f584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0f3d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/procesed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cf6e0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user Escribió un libro resultón, con gracejo,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user Lo prometido es deuda. Aquí la foto: .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user Bastante ñoña. Me jarté a llorar. De lo ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@user No sé nada acerca de eso, pero está clar...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user ¿En qué medio tienen su podcast esos, di...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14395</th>\n",
       "      <td>Lo que está ocurriendo hoy es una forma curios...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14396</th>\n",
       "      <td>@user Gracias, bellísima! Nos debemos un café-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14397</th>\n",
       "      <td>@user Es un análisis muy precipitado ese de qu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14398</th>\n",
       "      <td>Hace días veo en redes cómo algunos se burlan ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14399</th>\n",
       "      <td>\"Un cuento amargo. como un otoño largo. salien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets  labels\n",
       "0      @user Escribió un libro resultón, con gracejo,...       2\n",
       "1           @user Lo prometido es deuda. Aquí la foto: .       2\n",
       "2      @user Bastante ñoña. Me jarté a llorar. De lo ...       2\n",
       "3      @user No sé nada acerca de eso, pero está clar...       2\n",
       "4      @user ¿En qué medio tienen su podcast esos, di...       2\n",
       "...                                                  ...     ...\n",
       "14395  Lo que está ocurriendo hoy es una forma curios...       1\n",
       "14396  @user Gracias, bellísima! Nos debemos un café-...       1\n",
       "14397  @user Es un análisis muy precipitado ese de qu...       1\n",
       "14398  Hace días veo en redes cómo algunos se burlan ...       1\n",
       "14399  \"Un cuento amargo. como un otoño largo. salien...       1\n",
       "\n",
       "[14400 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "19b7e178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "def clear_stopwords(tweet):\n",
    "    return \" \".join([token.lemma_ for token in nlp(tweet) \n",
    "                     if not token.is_stop\n",
    "                     and not token.is_punct\n",
    "                     and not token.text.lower() in [\"@user\",\"political_party\", \"politician\", \"hashtag\", \"user\"]\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4a792a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet_clean\"] = df[\"tweets\"].apply(clear_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6829c458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    max_features = 50_000,\n",
    "    lowercase=True\n",
    ")\n",
    "X = vectorizer.fit_transform(df[\"tweet_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "590937ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class PoliticESDataset(Dataset):\n",
    "    def __init__(self, tweets, labels, vectorizer):\n",
    "        self.tweets = tweets\n",
    "        self.labels = labels\n",
    "        self.vectorizer = vectorizer\n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            'tweet': torch.tensor(self.vectorizer.transform([self.tweets[item]]).toarray()).to(torch.float32),\n",
    "            'label': self.labels[item]\n",
    "        }\n",
    "\n",
    "def create_data_loader(df, vectorizer, batch_size = 16):\n",
    "    return DataLoader(\n",
    "        PoliticESDataset(\n",
    "            tweets = df.tweets.to_numpy(),\n",
    "            labels = df.labels.to_numpy(),\n",
    "            vectorizer = vectorizer\n",
    "        ),\n",
    "        batch_size = batch_size,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "567fa316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TfIdfNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(TfIdfNetwork, self).__init__()\n",
    "        self.linear = nn.Linear(input_size,1024).to(device)\n",
    "        self.dropout = nn.Dropout(0.15).to(device)\n",
    "        self.linear1 = nn.Linear(1024, 4).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        t = self.linear(x.to(torch.float32).to(device))\n",
    "        t = self.dropout(t)\n",
    "        t = self.linear1(t)\n",
    "        return F.softmax(t, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d87a1d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def fit(model, loader, criterion, optimizer, total_steps):\n",
    "    model = model.train()\n",
    "    running_loss = 0.\n",
    "    for d in tqdm(loader, total = total_steps/16):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(d[\"tweet\"].squeeze())\n",
    "        loss = criterion(pred.to(device), d[\"label\"].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss\n",
    "\n",
    "def train(model, x, vectorizer, epochs=3, lr=1e-3):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loader = create_data_loader(x, vectorizer)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        loss = fit(model, loader, criterion, optimizer, len(x))\n",
    "        print(f'Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2d13d260",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 900/900.0 [00:20<00:00, 44.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1201.3125187158585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 900/900.0 [00:16<00:00, 54.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1141.0328485965729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 900/900.0 [00:16<00:00, 54.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1074.6670212745667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 900/900.0 [00:16<00:00, 54.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1012.0784994363785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 900/900.0 [00:16<00:00, 53.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 942.3421971797943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 900/900.0 [00:16<00:00, 54.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 886.6241592168808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 900/900.0 [00:16<00:00, 53.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 835.1191130876541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 900/900.0 [00:16<00:00, 54.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 794.7936396598816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame({\n",
    "    \"tweets\": df[\"tweet_clean\"],\n",
    "    \"labels\": df[\"labels\"]\n",
    "})\n",
    "model = TfIdfNetwork(X.shape[1])\n",
    "train(model, df_train, vectorizer, epochs=8, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "120e80e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, df_test, vectorizer):\n",
    "    model = model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    preds = np.array([])\n",
    "    loader = create_data_loader(df_test, vectorizer)\n",
    "    running_loss = .0\n",
    "    with torch.no_grad():\n",
    "        for d in loader:\n",
    "            pred = model(d[\"tweet\"].squeeze())\n",
    "            loss = criterion(pred, d[\"label\"].to(device))\n",
    "            running_loss += loss.item()\n",
    "            preds = np.concatenate((preds, torch.argmax(pred.cpu(), dim=1).numpy()))\n",
    "    return preds, running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8e981d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../../data/procesed_test.csv\")\n",
    "preds, test_loss = test(model, df_test, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b27b68d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.38      0.41      1636\n",
      "         1.0       0.42      0.30      0.35      1501\n",
      "         2.0       0.01      0.18      0.02        38\n",
      "         3.0       0.12      0.12      0.12       425\n",
      "\n",
      "    accuracy                           0.32      3600\n",
      "   macro avg       0.25      0.25      0.22      3600\n",
      "weighted avg       0.39      0.32      0.35      3600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(preds, df_test[\"labels\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
