{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c638c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DistilBertTokenizer, GPT2Tokenizer, GPT2LMHeadModel, DistilBertModel, BloomModel, BloomTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e583cd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8942c9aaac0e40e8af884479b27f4549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcd46978fab487bbd1e808d923d2fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "460dc28329744b62b7bd2ed54be115d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/361 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_beto = DistilBertTokenizer.from_pretrained('dccuchile/distilbert-base-spanish-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1c07ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Beto(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Beto, self).__init__()\n",
    "        self.max_len = 512\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer_beto = DistilBertTokenizer.from_pretrained('dccuchile/distilbert-base-spanish-uncased')\n",
    "        #self.tokenizer_bloom = BloomTokenizerFast.from_pretrained('bigscience/bloom')\n",
    "        self.encoder_beto = DistilBertModel.from_pretrained('dccuchile/distilbert-base-spanish-uncased')\n",
    "        #self.encoder_bloom = BloomModel.from_pretrained('bigscience/bloom')\n",
    "        self.dropout_beto = nn.Dropout(0.15)\n",
    "        #self.dropout_bloom = nn.Dropout(0.15)\n",
    "        \n",
    "        self.linear_gender = nn.Linear(768,768)\n",
    "        self.activation_gender = nn.Tanh()\n",
    "        self.dropout_gender = nn.Dropout(0.15)\n",
    "        self.linear_gender = nn.Linear(768,2)\n",
    "        self.out_gender = nn.Sigmoid()\n",
    "        \n",
    "        self.linear_profession = nn.Linear(768,768)\n",
    "        self.activation_profession = nn.Tanh()\n",
    "        self.dropout_profession = nn.Dropout(0.15)\n",
    "        self.linear_profession = nn.Linear(768,3)\n",
    "        self.out_profession = nn.Sigmoid()\n",
    "        \n",
    "        self.linear_ideology = nn.Linear(768,768)\n",
    "        self.activation_ideology = nn.Tanh()\n",
    "        self.dropout_ideology = nn.Dropout(0.15)\n",
    "        self.linear_ideology_1 = nn.Linear(768,2)\n",
    "        self.out_ideology = nn.Sigmoid()\n",
    "        \n",
    "        self.linear_ideology_multiclass = nn.Linear(768,768)\n",
    "        self.activation_ideology_multiclass = nn.Tanh()\n",
    "        self.dropout_ideology_multiclass = nn.Dropout(0.15)\n",
    "        self.linear_ideology_multiclass_1 = nn.Linear(768,4)\n",
    "        self.out_ideology_multiclass = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ids_beto, attention_masks_beto = self.tokenizer_beto(x).values()\n",
    "        for ids, attention_mask in zip(ids_beto, attention_masks_beto):\n",
    "            ids = ids[:self.max_len - 2]\n",
    "            ids = [4] + ids + [5]\n",
    "            padding_len_ids = self.max_len - len(ids)\n",
    "            attention_mask = attention_mask + ([0] * (padding_len_ids - 2))\n",
    "            ids = ids + ([0] * padding_len_ids)\n",
    "        #ids_bloom, attention_mask_bloom = self.tokenizer_bloom(x).values()\n",
    "        print(ids_beto)\n",
    "        embeding_beto = self.encoder_beto(\n",
    "            torch.LongTensor(ids_beto).to(self.device),\n",
    "            torch.LongTensor(attention_masks_beto).to(self.device)\n",
    "        )\n",
    "        #embeding_bloom = encoder_bloom(\n",
    "        #    torch.LongTensor(ids_bloom).to(self.device),\n",
    "        #    torch.LongTensor(attention_masks_bloom).to(self.device)\n",
    "        #)\n",
    "        embeding_beto = self.dropout_beto(embeding_beto)\n",
    "        #embeding_bloom = self.dropout_bloom(embeding_bloom)\n",
    "        #embeding = torch.cat(embeding_beto, embeding_bloom)\n",
    "        embeding = embeding_beto # Sustituir esta línea cuando se obtenga el otro encoder\n",
    "        x_gender = self.linear_gender(embeding)\n",
    "        x_gender = self.activation_gender(x_gender)\n",
    "        x_gender = self.dropout_gender(x_gender)\n",
    "        y_gender = self.out_gender(x_gender)\n",
    "        \n",
    "        x_profession = self.linear_profession(embeding)\n",
    "        x_profession = self.activation_profession(x_profession)\n",
    "        x_profession = self.dropout_profession(x_profession)\n",
    "        y_profession = self.out_profession(x_profession)\n",
    "        \n",
    "        x_ideology = self.linear_ideology(embeding)\n",
    "        x_ideology = self.activation_ideology(x_ideology)\n",
    "        x_ideology = self.dropout_ideology(x_ideology)\n",
    "        y_ideology = self.out_ideology(x_ideology)\n",
    "        \n",
    "        x_ideology_multiclass = self.linear_ideology_multiclass(embeding)\n",
    "        x_ideology_multiclass = self.activation_ideology_multiclass(x_ideology)\n",
    "        x_ideology_multiclass = self.dropout_ideology_multiclass(x_ideology)\n",
    "        y_ideology_multiclass = self.out_ideology_multiclass(x_ideology_multiclass)\n",
    "        \n",
    "        return [y_gender, y_profession, y_ideology, y_ideology_multiclass]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b3ea089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class PoliticESDataset(Dataset):\n",
    "    def __init__(self, tweet, gender, profession, ideology, ideology_mc):\n",
    "        self.tweet = tweet\n",
    "        self.gender = gender\n",
    "        self.profession = profession\n",
    "        self.ideology = ideology\n",
    "        self.ideology_mc = ideology_mc\n",
    "    def __len__(self):\n",
    "        return len(self.tweet)\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            'tweet': self.tweet[item],\n",
    "            'labels': [\n",
    "                self.gender[item],\n",
    "                self.profession[item],\n",
    "                self.ideology[item],\n",
    "                self.ideology[item]\n",
    "            ]\n",
    "        }\n",
    "\n",
    "def create_data_loader(df, batch_size = 16):\n",
    "    return DataLoader(\n",
    "        PoliticESDataset(\n",
    "            tweet = df.tweet.to_numpy(),\n",
    "            gender = df.gender.to_numpy(),\n",
    "            profession = df.profession.to_numpy(),\n",
    "            ideology = df.ideology_binary.to_numpy(),\n",
    "            ideology_mc = df.ideology_multiclass.to_numpy()\n",
    "        ),\n",
    "        batch_size = batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e68e1219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def criterion(loss_func, outputs, targets):\n",
    "    losses = 0\n",
    "    for output, target in zip(output, targets):\n",
    "        losses += loss_func(output, target)\n",
    "    return losses\n",
    "\n",
    "def fit(model, data_loader, total_steps, optimizer, loss_fn):\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    for i, entry in tqdm(enumerate(data_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(entry[\"tweet\"])\n",
    "        targets.append(ouput.item())\n",
    "        predictions.append(entry['labels'])\n",
    "        loss = criterion(loss_fn, output, entry['labels']).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            bingoes = []\n",
    "            for t,p in zip(targets, predictions):\n",
    "                for i in range (3):\n",
    "                    bingoes[i] += np.sum(targets[i]==predictions[i])\n",
    "                    print(f' precisión etiqueta {i}: {bingoes[i]}')\n",
    "            print(f' pérdida del lote: {last_loss}')\n",
    "            running_loss = 0.\n",
    "\n",
    "def train_model(model, train_dataset, eval_dataset, EPOCHS, batch_size, lr):\n",
    "    train_data_loader = create_data_loader(train_dataset, batch_size)\n",
    "    eval_data_loader = create_data_loader(eval_dataset, batch_size)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_acc, train_loss = fit(model, train_data_loader, len(train_dataset), optimizer, loss_fn)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1fde920c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/distilbert-base-spanish-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1894, 2909, 13079, 15292, 1019, 985, 9087, 30960, 2808, 15454, 1069, 10338, 1019, 1149, 1434, 1048, 1032, 4588, 1009, 1098, 1000, 3388, 8724, 1008, 1048, 1914, 23714, 1019, 1041, 4481, 11926, 1039, 1098, 1009, 3050, 1019, 1032, 10004, 11081, 1067, 4733, 1000, 8724, 1009, 13431, 1008, 1035, 985, 9087, 30960, 5], [4, 985, 9087, 30960, 1628, 1532, 1032, 4638, 20412, 2375, 2134, 30956, 1008, 1041, 1035, 2870, 1028, 4804, 1008, 5], [4, 985, 9087, 30960, 3547, 1019, 1792, 1318, 1039, 2657, 1019, 1086, 8601, 1019, 1040, 1578, 1076, 4393, 1009, 1032, 2030, 1019, 1081, 3151, 8358, 1040, 1009, 2048, 2252, 1008, 1028, 1032, 2035, 6537, 1041, 3297, 1008, 5], [4, 3194, 1008, 985, 9087, 30960, 1057, 1086, 8177, 1012, 7386, 995, 1351, 8861, 1022, 1012, 21177, 1081, 1527, 13014, 1012, 1067, 1041, 17363, 12527, 1190, 1019, 1777, 2484, 1041, 1054, 1094, 7508, 1152, 1076, 1792, 1195, 1212, 1076, 1069, 4841, 1008, 1388, 1019, 26532, 1086, 2332, 1097, 1027, 14059, 24331, 30955, 1040, 10183, 30964, 1008, 1054, 6505, 1035, 1848, 1009, 1085, 4603, 1009, 4599, 1008, 5], [4, 985, 9087, 30960, 1798, 1019, 15587, 1019, 1155, 3111, 3266, 2209, 21816, 30958, 1008, 1716, 1028, 2324, 1097, 5331, 1836, 3390, 1008, 5], [4, 977, 8753, 2770, 30959, 975, 1057, 5266, 1039, 3073, 1009, 2190, 1044, 14784, 29875, 1472, 1008, 1086, 2136, 1035, 1044, 12004, 1655, 13758, 1047, 1039, 15067, 1851, 1009, 977, 8753, 2770, 30959, 975, 1040, 1039, 1842, 16484, 1009, 9522, 9765, 5], [4, 1063, 17625, 30958, 1076, 1297, 1067, 1041, 4182, 2619, 30958, 1067, 4791, 2415, 1009, 19032, 6441, 1059, 1008, 1008, 1008, 1028, 1097, 1044, 2257, 1008, 5], [4, 2698, 1069, 1613, 1076, 1905, 1019, 1151, 1039, 9231, 1213, 14331, 4741, 10988, 1706, 30957, 1035, 6531, 21091, 30955, 1431, 1008, 22762, 1076, 2190, 1009, 1170, 12545, 1012, 1526, 9558, 1040, 3888, 1233, 2903, 1008, 1063, 1140, 9868, 1012, 2788, 1059, 1186, 1009, 1673, 1008, 3, 1035, 21008, 1008, 1032, 4360, 1899, 5941, 1040, 1067, 10762, 30959, 1174, 13924, 1233, 11003, 5], [4, 6552, 1322, 19584, 5023, 1048, 1067, 7282, 11170, 1012, 1032, 21490, 1040, 1012, 1136, 1097, 9224, 1149, 2035, 9416, 1008, 10258, 4903, 1035, 985, 9087, 30960, 1008, 1542, 1009, 2998, 1012, 1399, 3, 1008, 985, 9087, 30960, 1008, 985, 9087, 30960, 1008, 985, 9087, 30960, 5], [4, 985, 9087, 30960, 1772, 1075, 9324, 30770, 1320, 1785, 1044, 13319, 1040, 1183, 5069, 30010, 30958, 1008, 1069, 1381, 1052, 1032, 29376, 30978, 15841, 5], [4, 1039, 2934, 11046, 1009, 2612, 7935, 30958, 1097, 30285, 1148, 1012, 1032, 4288, 1009, 1032, 1041, 8245, 30978, 1039, 4496, 1009, 1993, 1179, 1139, 3101, 8336, 5], [4, 985, 9087, 30960, 20943, 30957, 1076, 2601, 1008, 1048, 9758, 1052, 1081, 2561, 1008, 1542, 1076, 1850, 3, 5], [4, 1212, 1019, 1195, 1048, 1140, 1926, 1059, 1009, 1754, 1059, 2152, 2066, 1019, 1067, 3308, 1054, 8514, 4852, 1069, 3859, 1035, 1277, 2833, 1008, 5], [4, 985, 9087, 30960, 1250, 1086, 3853, 1493, 1008, 2065, 1019, 1297, 1650, 1012, 2232, 1041, 1057, 27869, 1943, 7585, 1018, 1009, 1091, 2252, 1041, 1054, 12009, 1008, 5], [4, 3, 977, 1354, 5001, 3483, 975, 1054, 1428, 2703, 1372, 11881, 2135, 1019, 1372, 6901, 1008, 1337, 1086, 2392, 14183, 2066, 1048, 2045, 7323, 1008, 1054, 1012, 2703, 23984, 30959, 1050, 1012, 23858, 2483, 1008, 1320, 2338, 1019, 2345, 989, 1146, 1035, 1039, 977, 1354, 5001, 3483, 975, 5423, 23215, 1069, 5386, 1008, 1008, 3, 1202, 1028, 1086, 1041, 1578, 15724, 1131, 3, 5], [4, 2104, 1277, 2022, 1157, 4337, 1097, 7010, 1067, 5249, 1009, 1032, 2896, 2231, 1009, 2045, 1527, 1019, 1009, 1032, 3088, 3749, 1040, 20534, 993, 1032, 4804, 20505, 1067, 5249, 13263, 6246, 1040, 8659, 1009, 2232, 10052, 15864, 1008, 1149, 1028, 1032, 3132, 1008, 1008, 5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 52 at dim 1 (got 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22504\\2552875993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22504\\3959961953.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_dataset, eval_dataset, EPOCHS, batch_size, lr)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22504\\3959961953.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, data_loader, total_steps, optimizer, loss_fn)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tweet\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22504\\290770734.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids_beto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         embeding_beto = self.encoder_beto(\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids_beto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_masks_beto\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 52 at dim 1 (got 20)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "model = Beto()\n",
    "df = pd.read_csv(\"../../data/multilabel_encoded.csv\")\n",
    "X_train, X_val, df_train, df_val = train_test_split(df['tweet'], df[['gender', 'profession','ideology_binary', 'ideology_multiclass']], test_size=0.15, random_state = 100)\n",
    "df_val['tweet'] = X_val\n",
    "df_train['tweet'] = X_train\n",
    "train_model(model, df_train, df_val, EPOCHS = 2, batch_size = 16, lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b15fc072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>gender</th>\n",
       "      <th>profession</th>\n",
       "      <th>ideology_binary</th>\n",
       "      <th>ideology_multiclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>Tras varios ejercicios excelentes, @user sigue...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9166</th>\n",
       "      <td>@user Solo contra la izquierda rojiparda. Que ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>@user Juan, ellos son el pueblo, lo representa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8569</th>\n",
       "      <td>Sra. @user se lo vuelvo a explicar: Cuando ace...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>@user Pues, camarada, te falta conocer mujeres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8039</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14147</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6936</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24480 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  gender  profession  \\\n",
       "605    Tras varios ejercicios excelentes, @user sigue...     NaN         NaN   \n",
       "9166   @user Solo contra la izquierda rojiparda. Que ...     NaN         NaN   \n",
       "12082  @user Juan, ellos son el pueblo, lo representa...     NaN         NaN   \n",
       "8569   Sra. @user se lo vuelvo a explicar: Cuando ace...     NaN         NaN   \n",
       "575    @user Pues, camarada, te falta conocer mujeres...     NaN         NaN   \n",
       "...                                                  ...     ...         ...   \n",
       "12119                                                NaN     0.0         1.0   \n",
       "8039                                                 NaN     1.0         1.0   \n",
       "14147                                                NaN     1.0         0.0   \n",
       "6936                                                 NaN     0.0         0.0   \n",
       "5640                                                 NaN     1.0         2.0   \n",
       "\n",
       "       ideology_binary  ideology_multiclass  \n",
       "605                NaN                  NaN  \n",
       "9166               NaN                  NaN  \n",
       "12082              NaN                  NaN  \n",
       "8569               NaN                  NaN  \n",
       "575                NaN                  NaN  \n",
       "...                ...                  ...  \n",
       "12119              1.0                  3.0  \n",
       "8039               0.0                  1.0  \n",
       "14147              0.0                  1.0  \n",
       "6936               0.0                  1.0  \n",
       "5640               0.0                  0.0  \n",
       "\n",
       "[24480 rows x 5 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "88b63f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_loader = create_data_loader(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "894f882e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_gpt2 = GPT2LMHeadModel.from_pretrained('datificate/gpt2-small-spanish')\n",
    "input_ids_gpt2, at_mask_gpt2 = tokenizer_gpt2(['Hola buenas tardes', 'Hola buenas noches']).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "385b2b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[4, 1734, 2972, 10095, 5], [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_beto('Hola buenas tardes').values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea7fe9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 50257])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_gpt2(input_ids=torch.LongTensor(i), attention_mask=torch.FloatTensor(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41976fd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_beto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22504\\4036611867.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mencoder_beto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mat_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pooler_output'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'encoder_beto' is not defined"
     ]
    }
   ],
   "source": [
    "encoder_beto(torch.tensor(input_ids), torch.tensor(token_type), torch.tensor(at_mask))['pooler_output']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
